{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cooked-specialist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## You are using the Python ARM Radar Toolkit (Py-ART), an open source\n",
      "## library for working with weather radar data. Py-ART is partly\n",
      "## supported by the U.S. Department of Energy as part of the Atmospheric\n",
      "## Radiation Measurement (ARM) Climate Research Facility, an Office of\n",
      "## Science user facility.\n",
      "##\n",
      "## If you use this software to prepare a publication, please cite:\n",
      "##\n",
      "##     JJ Helmus and SM Collis, JORS 2016, doi: 10.5334/jors.119\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\pyart_env\\lib\\site-packages\\wradlib\\io\\radolan.py:939: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \"add_offset\": np.float(0),\n",
      "C:\\Users\\Admin\\anaconda3\\envs\\pyart_env\\lib\\site-packages\\wradlib\\io\\radolan.py:948: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \"add_offset\": np.float(0),\n",
      "C:\\Users\\Admin\\anaconda3\\envs\\pyart_env\\lib\\site-packages\\wradlib\\io\\xarray.py:495: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  (\"volume_number\", np.int),\n"
     ]
    }
   ],
   "source": [
    "# Packages for analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import dtype\n",
    "from netCDF4 import Dataset,date2num,num2date\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "# Packages for visuals\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Allows charts to appear in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import pyart\n",
    "import numpy.ma as ma\n",
    "import matplotlib.ticker as mticker\n",
    "from matplotlib import colors as c\n",
    "from matplotlib.colors import ListedColormap,BoundaryNorm\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeat\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import cartopy.geodesic as cargeo\n",
    "from shapely.geometry import Polygon\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "informal-deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UF:\n",
    "    def __init__(self,radar,shape_grid,lat_0, lon_0):\n",
    "        self.radar = radar\n",
    "        self.shape_grid = shape_grid\n",
    "        self.lat_0 = lat_0\n",
    "        self.lon_0 = lon_0\n",
    "    def calculate_attenuation_zphi(self):\n",
    "        fixed_fzl=3000\n",
    "        spec_at, pia_dict, cor_z, spec_diff_at, pida_dict, cor_zdr= pyart.correct.calculate_attenuation_zphi(\n",
    "            self.radar,\n",
    "            refl_field='reflectivity', \n",
    "            phidp_field= 'differential_phase',\n",
    "            zdr_field='differential_reflectivity',\n",
    "            temp_ref='fixed_fzl')\n",
    "        self.radar.add_field_like('reflectivity','Z_attenuation',cor_z['data'])\n",
    "        self.radar.add_field_like('differential_reflectivity','ZDR_attenuation', cor_zdr['data'])\n",
    "    def remove_noises(self):\n",
    "        #mask noises\n",
    "        mask_noises_CC=ma.masked_less(self.radar.fields['cross_correlation_ratio']['data'],0.85)\n",
    "        mask_noises_Z=ma.masked_less(self.radar.fields['reflectivity']['data'],0)\n",
    "        mask_noises_Z_atten=ma.masked_less(self.radar.fields['Z_attenuation']['data'],0)\n",
    "        mask_noises_KDP=ma.masked_less_equal(self.radar.fields['specific_differential_phase']['data'],0)\n",
    "        #for Z\n",
    "        rm_noises_Z_=np.ma.masked_array(self.radar.fields['reflectivity']['data'],mask_noises_CC.mask)\n",
    "        rm_noises_Z=np.ma.masked_array(rm_noises_Z_,mask_noises_Z.mask)\n",
    "        #for Z_atten\n",
    "        rm_noises_Z_atten_1=np.ma.masked_array(self.radar.fields['Z_attenuation']['data'],mask_noises_CC.mask) #rm_noises_Z_atten_2=np.ma.masked_array(rm_noises_Z_atten_1,mask_noises_Z.mask)\n",
    "        rm_noises_Z_atten=np.ma.masked_array(rm_noises_Z_atten_1,mask_noises_Z_atten.mask)\n",
    "        # for ZDR\n",
    "        rm_noises_ZDR_=np.ma.masked_array(self.radar.fields['differential_reflectivity']['data'],mask_noises_CC.mask)\n",
    "        rm_noises_ZDR=ma.masked_array(rm_noises_ZDR_,mask_noises_Z.mask)\n",
    "        #for ZDR_atten\n",
    "        rm_noises_ZDR_atten_1=np.ma.masked_array(self.radar.fields['ZDR_attenuation']['data'],mask_noises_CC.mask) #rm_noises_ZDR_atten_2=np.ma.masked_array(rm_noises_ZDR_atten_1,mask_noises_Z.mask)\n",
    "        rm_noises_ZDR_atten=ma.masked_array(rm_noises_ZDR_atten_1,mask_noises_Z_atten.mask)\n",
    "        #for KDP\n",
    "        rm_noises_KDP_=np.ma.masked_array(self.radar.fields['specific_differential_phase']['data'],mask_noises_CC.mask)\n",
    "        rm_noises_KDP_Z=ma.masked_array(rm_noises_KDP_,mask_noises_Z.mask)\n",
    "        rm_noises_KDP=ma.masked_array(rm_noises_KDP_Z,mask_noises_KDP.mask)\n",
    "        #add fields\n",
    "        self.radar.add_field_like('reflectivity','Z_removed_noises',rm_noises_Z,replace_existing=True)\n",
    "        self.radar.add_field_like('differential_reflectivity','ZDR_removed_noises', rm_noises_ZDR,replace_existing=True)\n",
    "        self.radar.add_field_like('reflectivity','Z_atten_removed_noises',rm_noises_Z_atten,replace_existing=True)\n",
    "        self.radar.add_field_like('differential_reflectivity','ZDR_atten_removed_noises', rm_noises_ZDR_atten,replace_existing=True)\n",
    "        self.radar.add_field_like('specific_differential_phase','KDP_removed_noises', rm_noises_KDP,replace_existing=True)\n",
    "    def convert_grid(self):\n",
    "        grid = pyart.map.grid_from_radars(\n",
    "            self.radar,\n",
    "            grid_shape=self.shape_grid, #Number of points in the grid (z, y, x)\n",
    "            grid_limits=((0, 9000), (-200000, 200000), (-200000, 200000)), # min-max tuong duong z,y,x\n",
    "            grid_origin = (self.lat_0, self.lon_0),\n",
    "            fields=['Z_removed_noises',\n",
    "                    'ZDR_removed_noises',\n",
    "                    'KDP_removed_noises',\n",
    "                    'Z_atten_removed_noises',\n",
    "                    'ZDR_atten_removed_noises'\n",
    "                    ],\n",
    "            roi_func='dist_beam',\n",
    "            weighting_function='cressman')\n",
    "        return grid\n",
    "    def convert_lat_lon(self, grid):\n",
    "        #conver distance to lat/lon\n",
    "        for i in range(self.shape_grid[1]):\n",
    "            geog = pyart.core.cartesian_to_geographic_aeqd(grid.x[\"data\"][i],grid.y[\"data\"][i],self.lon_0, self.lat_0, R=6370997.0)\n",
    "            grid.x[\"data\"][i] = geog[0]\n",
    "            grid.y[\"data\"][i] = geog[1]\n",
    "        return grid\n",
    "    def SHY95_algorithm(self,Zh):\n",
    "        Zh.mask=0\n",
    "        SHY95=np.zeros((self.shape_grid[1],self.shape_grid[2]))\n",
    "        #Step 1: Intensity\n",
    "        mask_st1=(Zh>=40)\n",
    "        SHY95[mask_st1]=1\n",
    "        #Step 2: Peakeness\n",
    "        def MBG(xo,yo,n,r,Zh): #Mean Background Reflectivity\n",
    "            y,x = np.ogrid[-xo:n-xo, -yo:n-yo]\n",
    "            mask = x*x + y*y <= r*r\n",
    "            Zh_none_O=Zh[xo,yo]\n",
    "            Zbg_ = np.ma.masked_array(Zh[mask], Zh[mask] ==Zh_none_O) # remove value cycle centers\n",
    "            Zbg = np.ma.masked_array(Zbg_, Zbg_ == 0) # remove 0 values\n",
    "            return Zbg\n",
    "        for xo in range (0,self.shape_grid[1],1):\n",
    "            for yo in range (0,self.shape_grid[2],1):\n",
    "                if SHY95[xo,yo]==0:\n",
    "                    Zbg=MBG(xo,yo,self.shape_grid[1],5.5,Zh).mean()\n",
    "                    deltaZh=Zh[xo,yo]-Zbg\n",
    "                    if (Zbg < 42.43) and (deltaZh >= (10-Zbg**2/180)):\n",
    "                        SHY95[xo,yo]=1\n",
    "                    elif Zbg>=42.43 and deltaZh>=0:\n",
    "                        SHY95[xo,yo]=1\n",
    "        #Step3: Surrounding area\n",
    "        def MBG_mask_r(xo,yo,n,r,): # mask array with r change\n",
    "            y,x = np.ogrid[-xo:n-xo, -yo:n-yo]\n",
    "            mask = x*x + y*y <= r*r\n",
    "            return mask\n",
    "        medium=[25,30,35,40]\n",
    "        for xo in range (0,self.shape_grid[1],1):\n",
    "            for yo in range (0,self.shape_grid[2],1):\n",
    "                if SHY95[xo,yo]==1:\n",
    "                    Zbg=MBG(xo,yo,self.shape_grid[1],5.5,Zh).mean()\n",
    "                    if Zbg < medium[0]:\n",
    "                        r=0.5 #1km\n",
    "                    elif Zbg>=medium[0] and Zbg <medium[1]:\n",
    "                        r=1   #2km\n",
    "                    elif Zbg>=medium[1] and Zbg <medium[2]: \n",
    "                        r=1.5 #3km\n",
    "                    elif Zbg>=medium[2] and Zbg <medium[3]:\n",
    "                        r=2   #4km\n",
    "                    elif Zbg>=medium[3]:\n",
    "                        r=2.5 #5km\n",
    "                    mask_st2=MBG_mask_r(xo,yo,self.shape_grid[1],r=r)\n",
    "                    SHY95[mask_st2]=2\n",
    "        #Step4: remaining areas as stratiform\n",
    "        for q in range (0,self.shape_grid[1],1):\n",
    "            for l in range (0,self.shape_grid[2],1):\n",
    "                if Zh[q,l] > 0 and SHY95[q,l] !=2:\n",
    "                    SHY95[q,l]=1\n",
    "        SHY95=ma.masked_equal(SHY95,0)\n",
    "        return SHY95\n",
    "    def SVM_algorithm(self,model,Zh_SVM,ZDR_SVM):\n",
    "        SVM=np.zeros((shape_grid[1],shape_grid[2]))\n",
    "        for xo in range (0,shape_grid[1],1):\n",
    "            for yo in range (0,shape_grid[2],1):\n",
    "                if Zh_SVM[xo,yo]!='masked' and ZDR_SVM[xo,yo]!='masked':\n",
    "                    resuls=model.predict([[Zh_SVM[xo,yo], ZDR_SVM[xo,yo]]])\n",
    "                    if resuls==2.0:\n",
    "                        SVM[xo,yo]=2\n",
    "                    elif resuls==1.0:\n",
    "                        SVM[xo,yo]=1\n",
    "        SVM=ma.masked_equal(SVM,0)\n",
    "        return SVM\n",
    "    def create_nc(self, fileout,SVM,Zh_SVM,ZDR_SVM,KDP_SVM,grid,format_time):\n",
    "        file = Dataset(fileout,'w')\n",
    "        file.title = \"SVM Algorithm files - netCDF \"\n",
    "        file.createDimension('longitude',self.shape_grid[2])\n",
    "        file.createDimension('latitude',self.shape_grid[1])\n",
    "        file.createDimension('time',1)\n",
    "        times = file.createVariable('time',dtype('i8').char,('time',))\n",
    "        lons = file.createVariable('longitude',dtype('f4').char,('longitude',))\n",
    "        lats = file.createVariable('latitude',dtype('f4').char,('latitude',))\n",
    "        lats.units = 'degrees_north'\n",
    "        lats.standard_name = \"Latitude\"\n",
    "        lats.long_name = \"Latitude\"\n",
    "        lats.axis = \"Y\"\n",
    "        lons.standard_name = \"Longitude\"\n",
    "        lons.long_name = \"Longitude\"\n",
    "        lons.axis = \"X\"\n",
    "        lons.units = 'degrees_east'\n",
    "        times.units = \"minutes since 2000-01-01 00:00\"\n",
    "        times.calendar = \"gregorian\"\n",
    "        times.standard_name = \"time\"\n",
    "        times.axis = \"T\"\n",
    "        lons[:] = grid.x[\"data\"]\n",
    "        lats[:] = grid.y[\"data\"]\n",
    "        times[:] = date2num(format_time,units=times.units,calendar=times.calendar)\n",
    "        Alg_SVM = file.createVariable('CS_SVM',dtype('f4').char,('time','latitude','longitude'))\n",
    "        Alg_SVM.units = 'C/S'\n",
    "        Alg_SVM[:] = SVM\n",
    "        #Alg_SHY95 = file.createVariable('CS_SHY95',dtype('f4').char,('time','latitude','longitude'))\n",
    "        #Alg_SHY95.units = 'C/S'\n",
    "        #Alg_SHY95[:] = SHY95\n",
    "        Alg_Zh = file.createVariable('Zh_1.5km',dtype('f4').char,('time','latitude','longitude'))\n",
    "        Alg_Zh.units = 'dBZ'\n",
    "        Alg_Zh[:] = Zh_SVM\n",
    "        Alg_ZDR = file.createVariable('ZDR_1.5km',dtype('f4').char,('time','latitude','longitude'))\n",
    "        Alg_ZDR.units = 'dB'\n",
    "        Alg_ZDR[:] = ZDR_SVM\n",
    "        Alg_KDP = file.createVariable('KDP_1.5km',dtype('f4').char,('time','latitude','longitude'))\n",
    "        Alg_KDP.units = 'dB'\n",
    "        Alg_KDP[:] = KDP_SVM\n",
    "        file.close()\n",
    "#Tạo giới hạn bán kính 200km    \n",
    "y,x = np.ogrid[-100:201-100, -100:201-100]\n",
    "mask = x*x + y*y > 100*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "incorporate-macintosh",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"A3/SVM_model_file_b4.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "victorian-opinion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/data/Radars/Embedded/1/\n",
      "PHA210405091004.RAWWW4F\n",
      "PHA210405092004.RAWWW4P\n",
      "PHA210405093004.RAWWW4Y\n",
      "PHA210405094003.RAWWW56\n",
      "PHA210405095004.RAWWW5E\n",
      "PHA210405100004.RAWWW5N\n",
      "PHA210405101004.RAWWW5Y\n",
      "PHA210405102004.RAWWW66\n",
      "PHA210405103004.RAWWW6E\n",
      "PHA210405104004.RAWWW6N\n",
      "PHA210405105004.RAWWW6X\n",
      "PHA210405110004.RAWWW75\n",
      "PHA210405111003.RAWWW7E\n",
      "PHA210405112004.RAWWW7N\n",
      "PHA210405113004.RAWWW7X\n",
      "PHA210405114004.RAWWW85\n",
      "PHA210405115004.RAWWW8D\n",
      "PHA210405120004.RAWWW8M\n",
      "PHA210405121004.RAWWW8X\n",
      "PHA210405122004.RAWWW95\n",
      "PHA210405123003.RAWWW9D\n",
      "PHA210405124004.RAWWW9M\n",
      "PHA210405125004.RAWWW9W\n",
      "PHA210405130004.RAWWWA4\n"
     ]
    }
   ],
   "source": [
    "#Testing-Embedded:1,2,8,9,10,12,13,14,15/Full stratiform:1,6,7,8,10,12,13,14,15/Squall line:2,6,7,9,10,12,13,14,15\n",
    "Case='Embedded'\n",
    "Case_dic={Case:[1]}\n",
    "for r in Case_dic[Case]:\n",
    "    linkRAW='D:/data/Radars/'+Case+'/'+str(r)+'/'\n",
    "    print(linkRAW)\n",
    "    os.mkdir('E:/SVM_netCDF/'+Case+'/'+str(r))\n",
    "    linkOUT='E:/SVM_netCDF/'+Case+'/'+str(r)+'/'\n",
    "    for file_name in os.listdir(linkRAW):\n",
    "        radar = pyart.io.read_sigmet(linkRAW+file_name)\n",
    "        lat_0 = radar.latitude['data'][0]\n",
    "        lon_0 = radar.longitude['data'][0]\n",
    "        shape_grid = (7, 201,201)\n",
    "        UF_File = UF(radar, shape_grid, lat_0, lon_0)\n",
    "        UF_File.calculate_attenuation_zphi()\n",
    "        UF_File.remove_noises()\n",
    "        grid = UF_File.convert_grid()\n",
    "        grid_lat_lon = UF_File.convert_lat_lon(grid)\n",
    "        Zh_SVM=np.ma.masked_array(grid.fields['Z_removed_noises']['data'][1,:,:],mask)\n",
    "        ZDR_SVM=np.ma.masked_array(grid.fields['ZDR_removed_noises']['data'][1,:,:],mask)\n",
    "        KDP_SVM=np.ma.masked_array(grid.fields['KDP_removed_noises']['data'][1,:,:],mask)\n",
    "        Zh_atten=np.ma.masked_array(grid.fields['Z_atten_removed_noises']['data'][1,:,:],mask)\n",
    "        ZDR_atten=np.ma.masked_array(grid.fields['ZDR_atten_removed_noises']['data'][1,:,:],mask)\n",
    "        SVM=UF_File.SVM_algorithm(model,Zh_SVM,ZDR_SVM)\n",
    "        #SHY95=np.ma.masked_array(UF_File.SHY95_algorithm(grid.fields['Z_removed_noises']['data'][1,:,:]),mask)\n",
    "        format_string_time = \"%Y-%m-%dT%H:%M\"\n",
    "        ti=radar.time['units'][14:-4]\n",
    "        format_time=datetime.strptime(ti, format_string_time)\n",
    "        UF_File.create_nc(linkOUT+\"SVM\"+file_name[3:15]+\".nc\",SVM,Zh_atten,ZDR_atten,KDP_SVM,grid_lat_lon,format_time)\n",
    "        print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-house",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-prairie",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
